## ğŸ“Œ README.md â€“ Projeto de Mensageria com Kafka (Java)

### ğŸ–¥ï¸ Disciplina: Software Concorrente e DistribuÃ­do

### ğŸ“š Curso: Bacharelado em Engenharia de Software

### ğŸ‘¥ Integrantes:

- Guilherme GonÃ§alves Dutra de MendonÃ§a [202201692]
- Hugo Moreno I Veiga Jardim [202201693]
- Mikael Borges de Oliveira e Silva Junior [202201708]

---

## âœ… VisÃ£o Geral

Este projeto Ã© uma prova de conceito de microserviÃ§os distribuÃ­dos, em que cada serviÃ§o Ã© desacoplado e comunica-se de forma assÃ­ncrona atravÃ©s de **Apache Kafka**. O fluxo completo Ã©:

1. **Order-Service**
   - Recebe requisiÃ§Ãµes HTTP `POST /orders`
   - Cria um objeto `Order` com ID, timestamp e lista de itens
   - Publica esse objeto em JSON no tÃ³pico Kafka `orders`
2. **Inventory-Service**
   - LÃª mensagens JSON de `orders`
   - Converte cada JSON em um DTO local `OrderDTO` (para nÃ£o depender de classes de outro serviÃ§o)
   - Simula reserva de estoque (80% de chance de sucesso)
   - Cria um objeto `InventoryEvent` e publica em JSON no tÃ³pico `inventory-events`
3. **Notification-Service**
   - LÃª mensagens JSON de `inventory-events`
   - Converte cada JSON em um DTO local `InventoryEvent`
   - Loga uma mensagem simulando envio de e-mail/SMS

Cada serviÃ§o roda em **porta distinta** (8383, 8081, 8082) para evitar conflitos e facilitar testes paralelos.

---

## âœ… Requisitos

- **Java 11+** e **Apache Maven 3.6+**
- **Docker** + **Docker Compose** (v3.8+)
- Cliente HTTP: **curl**, **Postman** ou **Insomnia**
- (Windows) Git Bash ou PowerShell para executar scripts

---

## ğŸš€ Como Rodar o Projeto

### 1. Clonar o RepositÃ³rio

```bash
git clone https://github.com/kamamijr/projeto_kafka.git
cd projeto_kafka
```

chmod +x infra/startup_infra.sh
./infra/startup_infra.sh

### 2. Subir o Kafka e Criar os TÃ³picos

```bash
chmod +x infra/startup_infra.sh
./infra/startup_infra.sh
```

#### ğŸ” O que esse script faz:

- Entra na pasta `infra`
- Sobe os containers do **Zookeeper**, **Kafka** e **Kafka-UI**:

  ```bash
  cd infra
  docker-compose up -d
  ```

- Aguarda \~15 segundos atÃ© o Kafka estar disponÃ­vel
- Cria os tÃ³picos `orders` e `inventory-events`, cada um com **3 partiÃ§Ãµes**

#### âœ… Por que isso importa:

- Evita erros como **"tÃ³pico nÃ£o encontrado"**
- Kafka-UI disponÃ­vel em: [http://localhost:8080](http://localhost:8080)

---

### 3. Iniciar os ServiÃ§os Java

> âš ï¸ Execute cada serviÃ§o em **um terminal separado**:

#### 3.1 Order-Service

```bash
cd order-service
mvn clean spring-boot:run
```

#### 3.2 Inventory-Service

```bash
cd inventory-service
mvn clean spring-boot:run
```

#### 3.3 Notification-Service

```bash
cd notification-service
mvn clean spring-boot:run
```

#### âš™ï¸ Detalhes TÃ©cnicos:

- Cada serviÃ§o usa **Spring Boot** com **spring-kafka**
- ConfiguraÃ§Ã£o do Kafka feita via `application.yml`
- Mensagens serializadas em **JSON** com `JsonSerializer` / `JsonDeserializer`

---

### ğŸ”ª Testando o Fluxo

#### Enviar um Pedido (Linux/macOS)

```bash
curl -i -X POST http://localhost:8383/orders \
  -H "Content-Type: application/json" \
  -d '{
        "items":[
          { "sku":"ABC", "qty":2 },
          { "sku":"XYZ", "qty":1 }
        ]
      }'
```

#### Enviar um Pedido (Windows CMD)

```cmd
curl -i -X POST "http://localhost:8383/orders" -H "Content-Type: application/json" -d "{\"items\":[{\"sku\":\"ABC\",\"qty\":2},{\"sku\":\"XYZ\",\"qty\":1}]}"
```

#### ğŸ“¬ O que acontece:

- **Order-Service** retorna `200 OK` com o JSON do pedido criado.
- **Inventory-Service** consome o JSON, desserializa em `OrderDTO` e publica um `InventoryEvent`.
- **Notification-Service** consome o evento, desserializa em `InventoryEvent` e loga:

```bash
Notification: Pedido <ID> estÃ¡ com status 'SUCCESS'. Enviando e-mail/SMS...
```

---

### ğŸ”§ Pontos Importantes do Desenvolvimento

- **DTOs locais** em cada serviÃ§o (`OrderDTO`, `InventoryEvent`) evitam dependÃªncia entre mÃ³dulos.

- **JSON puro:**

  - `JsonSerializer` envia dados em JSON sem cabeÃ§alhos de tipo.
  - `JsonDeserializer` usa `spring.json.value.default.type` para mapear JSON para DTO.
  - `spring.json.add.type.headers=false`: evita cabeÃ§alhos extras, melhorando a interoperabilidade.

- **auto-offset-reset=latest**: garante que consumidores leiam apenas mensagens recentes, ignorando antigas com formatos diferentes.

- **Script startup_infra.sh:**

  - Remove volumes antigos com `docker-compose down -v`
  - Espera os containers e a porta `9092` estarem prontos antes de criar tÃ³picos

- **Portas distintas** para os serviÃ§os: facilita testes locais sem conflitos

---

### ğŸ“ Estrutura de Pastas

```
.
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ setup_inicial.sh
â”œâ”€â”€ order-service/
â”‚   â”œâ”€â”€ pom.xml
â”‚   â””â”€â”€ src/
â”œâ”€â”€ inventory-service/
â”‚   â”œâ”€â”€ pom.xml
â”‚   â””â”€â”€ src/
â””â”€â”€ notification-service/
    â”œâ”€â”€ pom.xml
    â””â”€â”€ src/
```

## Diagramas

## Diagrama de Classes

![Diagrama-de-classes2-mensageria-java](https://github.com/user-attachments/assets/0b78ef1d-0d5a-49b3-9f7d-02d381aa5b98)

## Diagrama de SequÃªncia

![Diagrama-de-sequÃªncia-mensageria-java](https://github.com/user-attachments/assets/af5cc485-5dda-4802-8d77-93a3153047c1)

## Diagrama de Casos de Uso

![Diagrama-casos-de-uso-mensageria-java](https://github.com/user-attachments/assets/c7b9b7ce-bc39-40aa-a466-79f5c1ba2b5f)

## Requisitos NÃ£o Funcionais

## âœ… 1. Escalabilidade â€“ Como conseguir com Kafka?

O **Apache Kafka** Ã© altamente escalÃ¡vel por natureza, pois suporta:

- **PartiÃ§Ãµes por tÃ³pico**: cada tÃ³pico (como `orders` e `inventory-events`) pode ter mÃºltiplas partiÃ§Ãµes, permitindo que vÃ¡rias instÃ¢ncias de consumidores leiam dados em paralelo.
- **Grupos de consumidores**: serviÃ§os como o `Inventory-Service` podem ser replicados (escalados horizontalmente), e o Kafka balanceia automaticamente as partiÃ§Ãµes entre as instÃ¢ncias do mesmo grupo (`inventory-group`).
- **Produtores e consumidores independentes**: os serviÃ§os sÃ£o desacoplados, o que permite escalar cada um separadamente conforme a carga (por exemplo, posso escalar o `Notification-Service` sem impactar os demais).

---

## âœ… 2. TolerÃ¢ncia Ã  falha â€“ O que significa e como o Kafka ajuda?

**TolerÃ¢ncia Ã  falha** Ã© a capacidade de o sistema continuar funcionando mesmo que partes dele falhem.

Se o `Inventory-Service` cair enquanto consome o tÃ³pico `orders`, o Kafka **mantÃ©m as mensagens na fila**. Quando o serviÃ§o for reiniciado, ele continuarÃ¡ consumindo a partir do **Ãºltimo offset salvo**.

AlÃ©m disso, o Kafka oferece:

- **ConfiguraÃ§Ã£o de `acks`, `retries` e armazenamento persistente**, garantindo que mensagens nÃ£o se percam em falhas.
- **ReplicaÃ§Ã£o de partiÃ§Ãµes**, aumentando a resiliÃªncia caso um nÃ³ do Kafka falhe (ex: `--replication-factor=2` ou `3`, com mÃºltiplos brokers).

---

## âœ… 3. IdempotÃªncia â€“ O que Ã© e como garantir?

**IdempotÃªncia** significa que a repetiÃ§Ã£o da mesma operaÃ§Ã£o **tem o mesmo efeito** da primeira execuÃ§Ã£o.

Em sistemas distribuÃ­dos, mensagens podem ser reenviadas. EntÃ£o Ã© essencial evitar efeitos colaterais duplicados.

Por exemplo:  
O `Inventory-Service` pode receber duas vezes o mesmo pedido. Para ser idempotente, Ã© necessÃ¡rio verificar se o `orderId` **jÃ¡ foi processado** antes de reservar estoque novamente ou publicar outro evento.

### ğŸ› ï¸ Como garantir:

- Usar um **banco de dados** ou **cache** (como Redis ou Postgres) para registrar pedidos processados.
- Em sistemas simples, usar um **mapa em memÃ³ria** para guardar `orderId`s jÃ¡ tratados.

AlÃ©m disso:

- Os **producers Kafka** suportam `enable.idempotence=true`, que evita que mensagens duplicadas sejam publicadas, mesmo em caso de falhas ou reenvios.

## ğŸ§ª Teste de IntegraÃ§Ã£o Automatizado

O projeto inclui um teste de integraÃ§Ã£o no `inventory-service` que valida o fluxo real de eventos entre os microserviÃ§os usando o Kafka rodando via Docker. O teste publica um pedido no tÃ³pico `orders` e verifica se o evento correspondente Ã© publicado corretamente no tÃ³pico `inventory-events`. Isso garante que o sistema estÃ¡ funcionando de ponta a ponta, simulando o ambiente de produÃ§Ã£o.
